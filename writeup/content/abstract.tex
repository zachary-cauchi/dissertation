\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

In the field of \gls{ai} vision-language tasks, \gls{vcr} stands out as an interesting case of requiring an \gls{ai} model to not only predict correct answers, but explain why those answers were chosen.
The \gls{snmn} model, while not designed to target \gls{vcr} tasks, also stands out for different reasons; it is a compositional model which tries to predict answers to \gls{vqa} tasks via a memory stack used to store the intermediate steps taken to predict a final answer.
These intermediate outputs can then be visualised to better understand how the model is trying to arrive at its conclusion.
This study adapts the \gls{snmn} model to predict answers and rationales in the \gls{vcr} tasks --- attempting to obtain an accuracy better than random guessing and at most within 20\% of more recent state-of-the-art models --- while still retaining use of its memory stack to provide intermediate outputs.
The results do not reach state-of-the-art accuracy and also showed signs of overfitting, but do suggest avenues for future work that may yet improve the model.
