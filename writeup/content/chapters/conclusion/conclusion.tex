\chapter{Conclusion}
\label{chp:conclusion}

To conclude, this dissertation has explored how a subset of computer language-vision models known as the \gls{nmn} models could be adapted to not only answer questions about an image, but also provide the reasoning behind its answer.
Several computer language-vision tasks were explored --- namely \gls{vqa}, \gls{vcr}, and VisDial --- and the model-training challenges that they target.
A selection of \gls{nmn} models were explored to identify what makes these models desirable among other language-vision model types, namely their compositional nature and their explainability.
This dissertation presented how one such \gls{nmn} known as the \gls{snmn} performs on the \gls{vcr} dataset, including the modifications needed to the make the model support the dataset.
The results are not state-of-the-art --- only comparing in accuracy to the reference \gls{vcr} model in the Q\rightarrow{}A and QA\rightarrow{}R tasks --- and struggles when longer input text sequences are supplied.
Future work may wish to explore the emergence of generalised models (such as \gls{lnmn} and \gls{mmn}) for possibly better results.
Additional work may explore new training strategies, especially to minimise training errors such as those encountered during this dissertation.

\todo[inline]{Discuss the possibility of a QR\rightarrow{}A task type to explore if the ordering sentences would make a difference in prediction (a sort of introduction (Q), methodology (R) and conclusion (A) pattern).}
