\chapter{Conclusion}
\label{chp:conclusion}

To conclude, this dissertation has explored how a subset of computer language-vision models known as the \gls{nmn} models could be adapted to answer questions about an image.
Several computer language-vision tasks were explored --- namely \gls{vqa}, \gls{vcr}, and VisDial --- and the model-training challenges that they target.
A selection of \gls{nmn} models were explored to identify what makes these models desirable among other language-vision model types, namely their compositional nature and their explainability.
This dissertation presented how one such \gls{nmn} known as the \gls{snmn} performs on the \gls{vcr} dataset, including the modifications needed to the make the model support the dataset.
The results are not state-of-the-art --- only compare to the reference \gls{vcr} model in two of three tasks --- and suffers when longer input text sequences are supplied.
Future work may wish to explore the emergence of generalised models (such as \gls{lnmn} and \gls{mmn}) for possibly better results.
Additional work may explore new training strategies, especially to minimise training errors such as those encountered during this dissertation.
