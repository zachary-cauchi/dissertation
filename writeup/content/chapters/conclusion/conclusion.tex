\chapter{Conclusion}
\label{chp:conclusion}

To conclude, this study has explored how a subset of computer language-vision models known as the \gls{nmn} models could be adapted to not only answer questions about an image, but also provide the reasoning behind its answer.
Several computer language-vision tasks were explored --- namely \gls{vqa}, \gls{vcr}, and VisDial --- and the model-training challenges that they target.
A selection of \gls{nmn} models were explored to identify what makes these models desirable among other language-vision model types, namely their compositional nature and their explainability.
This study presented how one such \gls{nmn} known as the \gls{snmn} performs on the \gls{vcr} dataset, including the modifications needed to the make the model support the dataset.
The results are not state-of-the-art --- only comparing in accuracy to the reference \gls{vcr} model in the Q\rightarrow{}A and QA\rightarrow{}R tasks --- and struggles when longer input text sequences are supplied.
Future work may wish to explore the emergence of generalised models (such as \gls{lnmn}, \gls{mmn}) for possibly better results.
Additional work may explore new training strategies, especially to minimise training errors such as those encountered during this study (\citeauthor{zellers_merlot_2022}'s MERLOT-RESERVE demonstrated that training on a generalised dataset and fine-tuning onto \gls{vcr} produces a model with very good accuracy).
Lastly, the qualitative analysis of the QAp\rightarrow{}R model results suggested that two models may perform better at Q\rightarrow{}AR than one due to how the accuracy of the QAp\rightarrow{}R model and seed model produced a combined accuracy higher than the Q\rightarrow{}AR model.
